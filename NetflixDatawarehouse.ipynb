{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2019-09-09\n",
      "1    2016-09-09\n",
      "2    2018-09-08\n",
      "3    2018-09-08\n",
      "4    2017-09-08\n",
      "Name: date_added, dtype: object\n"
     ]
    }
   ],
   "source": [
    "parse_dates = ['date_added']\n",
    "netflix_titles = pd.read_csv('mycsvfile.csv', parse_dates=parse_dates) # using pandas to read the csv file\n",
    "netflix_titles['date_added'] = pd.to_datetime(netflix_titles['date_added'], errors='coerce') # change the date format to YYYY-MM-DD for column \"date_added\"\n",
    "netflix_titles['date_added'] = netflix_titles['date_added'].dt.strftime(\"%Y-%m-%d\")\n",
    "fullList = netflix_titles['title'].values.tolist()\n",
    "print(netflix_titles['date_added'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDim = netflix_titles.drop(['date_added', 'release_year', 'rating','listed_in'], axis=1) # delete the columns that are not needed\n",
    "showDim = showDim.where((pd.notnull(showDim)), None) # convert empty values to \"None\" values\n",
    "showDimList = []\n",
    "for row in showDim.values.tolist():\n",
    "    showDimList.append(tuple(row)) # format data into a list of tuples before inserting to database\n",
    "\n",
    "# showDimList: show data for show_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_origionals = pd.read_csv('netflix_originals.csv') # using pandas to read the csv file\n",
    "netflix_origionals = netflix_origionals[['Title','Seasons','Length','Netflix Exclusive Regions','Status']] # select the columns to keep\n",
    "netflix_origionals = netflix_origionals.where((pd.notnull(netflix_origionals)), None) # convert empty values to \"None\" values\n",
    "netflix_origionals.drop_duplicates(subset =\"Title\", \n",
    "                     keep = 'first', inplace = True) # delete duplicate values \n",
    "netflix_origionalsList = [tuple(l) for l in netflix_origionals.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "#print(netflix_origionalsList) #: data for original_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_stocks = pd.read_csv('NFLX.csv', parse_dates=['Date']) # using pandas to read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDim = pd.DataFrame({'date': pd.date_range(start='2002-05-23', end='2020-08-03')}) # create a dataframe that has dates ranging from 2002-05-23 to 2020-08-03\n",
    "dateDim['date_id'] = dateDim.index + 1 # create date_id column and assign id numbers starting from 1\n",
    "dateDim['date'] = dateDim['date'].dt.strftime(\"%Y-%m-%d\") # format date column to YYYY-MM-DD\n",
    "dateDim['year'] = pd.DatetimeIndex(dateDim['date']).year # using the year information from date colunn to create year column\n",
    "dateDim = dateDim.reindex(columns=['date_id','date','year']) # re-arrange the order of columns\n",
    "#dateDim.date = pd.to_datetime(dateDim.date)\n",
    "dateDim.date_id = dateDim.date_id.astype(str) # convert data in date column to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDimList = [tuple(l) for l in dateDim.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "# dateDimList: data for date_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDim.date = pd.to_datetime(dateDim.date) # convert data in date column to datatype date\n",
    "\n",
    "factsStockDF = pd.merge(netflix_stocks, dateDim, left_on='Date', right_on='date', how='inner') # inner join dataframes netflix_stocks and dataDim on date\n",
    "factsStockDF = factsStockDF.drop(['Date', 'date', 'year'], axis=1) # delete columns that are not needed\n",
    "factsStockDF = factsStockDF.reindex(columns=['date_id','Open','High','Low','Close','Adj Close', 'Volume']) # re-arrange the order of columns\n",
    "# factsStockDF['Date'] = factsStockDF['Date'].dt.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsStockList = [tuple(l) for l in factsStockDF.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "# factsStockList: data for facts_stock_prices table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRating = pd.merge(netflix_titles, netflix_origionals, left_on='title', right_on='Title', how='left') # left join dataframes netflix_titles and netflix_originals on titles\n",
    "factsRating.date_added = pd.to_datetime(factsRating.date_added) # convert data in date_added column to datatype date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = pd.merge(factsRating, dateDim, left_on='date_added', right_on='date', how='left') # left join dataframes factsRating and dateDim on date_added/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = factsRatingDF[['show_id','title','Title','date_id','rating']] # select only columns needed \n",
    "# factsRatingDF['date_id'] = factsRatingDF['date_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = factsRatingDF.where((pd.notnull(factsRatingDF)), None) # convert empty values to \"None\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingList = [tuple(l) for l in factsRatingDF.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "#print(factsRatingList) # data for facts_IMDB_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Establish the database connection\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Drop the table if it already exists\n",
    "cursor.execute(\"DROP TABLE IF EXISTS show_dim;\")\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable1 = \"\"\"CREATE TABLE show_dim(\n",
    "                 show_id INT not null,\n",
    "                 type VARCHAR(255) null,\n",
    "                 title VARCHAR(255) not null,\n",
    "                 director VARCHAR(255) null,\n",
    "                 cast MEDIUMTEXT null,\n",
    "                 country VARCHAR(255) null,\n",
    "                 duration VARCHAR(255) null,\n",
    "                 description MEDIUMTEXT null,\n",
    "                 PRIMARY KEY (show_id, title));\"\"\"\n",
    "\n",
    "cursor.execute(createTable1)\n",
    "\n",
    "insertData1 = \"INSERT INTO show_dim VALUES (%s,%s,%s,%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData1, showDimList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS original_dim;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable2 = \"\"\"CREATE TABLE original_dim(\n",
    "                  original_title VARCHAR(255) not null,\n",
    "                  seasons VARCHAR(255) null,\n",
    "                  length VARCHAR (255) null,\n",
    "                  regions VARCHAR (255) null,\n",
    "                  status VARCHAR (255) null,\n",
    "                  PRIMARY KEY (original_title));\"\"\"\n",
    "\n",
    "cursor.execute(createTable2)\n",
    "\n",
    "insertData2 = \"INSERT INTO original_dim VALUES (%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData2, netflix_origionalsList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create date_dim table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS date_dim;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable3 = \"\"\"CREATE TABLE date_dim(\n",
    "                  date_id VARCHAR(50) not null,\n",
    "                  date DATE null,\n",
    "                  year INT null,\n",
    "                  PRIMARY KEY (date_id));\"\"\"\n",
    "\n",
    "cursor.execute(createTable3)\n",
    "\n",
    "insertData3 = \"INSERT INTO date_dim VALUES (%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData3, dateDimList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create facts_imdb_rating table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS facts_imdb_rating;\")\n",
    "\n",
    "# Tạo bảng mới\n",
    "createTable5 = \"\"\"\n",
    "CREATE TABLE facts_imdb_rating (\n",
    "    show_id INT NOT NULL,\n",
    "    title VARCHAR(255) NOT NULL,\n",
    "    original_title VARCHAR(255),\n",
    "    date_id VARCHAR(50),\n",
    "    rating FLOAT,\n",
    "    PRIMARY KEY (show_id),\n",
    "    FOREIGN KEY (show_id) REFERENCES show_dim(show_id),\n",
    "    FOREIGN KEY (original_title) REFERENCES original_dim(original_title),\n",
    "    FOREIGN KEY (date_id) REFERENCES date_dim(date_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(createTable5)\n",
    "\n",
    "insertData5 = \"INSERT INTO facts_imdb_rating VALUES (%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData5, factsRatingList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bảng movie_genre và liên kết đã được thiết lập thành công.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kết nối với cơ sở dữ liệu\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Tạo bảng movie_genre\n",
    "\n",
    "# Chuẩn bị dữ liệu cho movie_genre\n",
    "# Ví dụ: netflix_titles có cột \"show_id\" và \"listed_in\"\n",
    "netflix_titles['genres'] = netflix_titles['listed_in'].str.split(', ')\n",
    "\n",
    "# Tạo danh sách các thể loại duy nhất\n",
    "unique_genres = set(genre for genres in netflix_titles['genres'] for genre in genres)\n",
    "genre_dict = {genre: idx+1 for idx, genre in enumerate(unique_genres)}\n",
    "\n",
    "# Chèn các thể loại vào bảng genre_dim\n",
    "cursor.execute(\"DROP TABLE IF EXISTS genre_dim;\")\n",
    "create_genre_dim = \"\"\"\n",
    "CREATE TABLE genre_dim (\n",
    "    genre_id INT AUTO_INCREMENT,\n",
    "    genre_name VARCHAR(255) NOT NULL,\n",
    "    PRIMARY KEY (genre_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_genre_dim)\n",
    "\n",
    "insert_genre_dim = \"INSERT INTO genre_dim (genre_name) VALUES (%s);\"\n",
    "cursor.executemany(insert_genre_dim, [(genre,) for genre in unique_genres])\n",
    "db.commit()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS show_genre;\")\n",
    "\n",
    "create_movie_genre = \"\"\"\n",
    "CREATE TABLE show_genre (\n",
    "    show_id INT NOT NULL,\n",
    "    genre_id INT NOT NULL,\n",
    "    PRIMARY KEY (show_id, genre_id),\n",
    "    FOREIGN KEY (show_id) REFERENCES facts_imdb_rating(show_id),\n",
    "    FOREIGN KEY (genre_id) REFERENCES genre_dim(genre_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_movie_genre)\n",
    "\n",
    "# Chuẩn bị dữ liệu cho movie_genre\n",
    "show_genres = []\n",
    "for _, row in netflix_titles.iterrows():\n",
    "    movie_id = row['show_id']\n",
    "    for genre in row['genres']:\n",
    "        show_genres.append((movie_id, genre_dict[genre]))\n",
    "\n",
    "# Chèn dữ liệu vào bảng movie_genre\n",
    "insert_movie_genre = \"INSERT INTO show_genre (show_id, genre_id) VALUES (%s, %s);\"\n",
    "cursor.executemany(insert_movie_genre, show_genres)\n",
    "db.commit()\n",
    "\n",
    "# Đóng kết nối\n",
    "db.close()\n",
    "\n",
    "print(\"Bảng movie_genre và liên kết đã được thiết lập thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create facts_stock_prices table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS facts_stock_prices;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable6 = \"\"\"CREATE TABLE facts_stock_prices(\n",
    "                  date_id VARCHAR(50) not null,\n",
    "                  open FLOAT null,\n",
    "                  high FLOAT null,\n",
    "                  low FLOAT null,\n",
    "                  close FLOAT null,\n",
    "                  adj_close FLOAT null,\n",
    "                  volume FLOAT null,\n",
    "                  PRIMARY KEY (date_id),\n",
    "                  FOREIGN KEY (date_id) REFERENCES date_dim(date_id)\n",
    "                  );\"\"\"\n",
    "\n",
    "cursor.execute(createTable6)\n",
    "\n",
    "insertData6 = \"INSERT INTO facts_stock_prices VALUES (%s,%s,%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData6, factsStockList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
