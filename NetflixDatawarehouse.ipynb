{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2019-09-09\n",
      "1    2016-09-09\n",
      "2    2018-09-08\n",
      "3    2018-09-08\n",
      "4    2017-09-08\n",
      "Name: date_added, dtype: object\n"
     ]
    }
   ],
   "source": [
    "parse_dates = ['date_added']\n",
    "netflix_titles = pd.read_csv('mycsvfile.csv', parse_dates=parse_dates) # using pandas to read the csv file\n",
    "netflix_titles['date_added'] = pd.to_datetime(netflix_titles['date_added'], errors='coerce') # change the date format to YYYY-MM-DD for column \"date_added\"\n",
    "netflix_titles['date_added'] = netflix_titles['date_added'].dt.strftime(\"%Y-%m-%d\")\n",
    "fullList = netflix_titles['title'].values.tolist()\n",
    "print(netflix_titles['date_added'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "showDim = netflix_titles.drop(['date_added', 'release_year', 'rating','listed_in'], axis=1) # delete the columns that are not needed\n",
    "showDim = showDim.where((pd.notnull(showDim)), None) # convert empty values to \"None\" values\n",
    "showDimList = []\n",
    "for row in showDim.values.tolist():\n",
    "    showDimList.append(tuple(row)) # format data into a list of tuples before inserting to database\n",
    "\n",
    "# showDimList: show data for show_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_origionals = pd.read_csv('netflix_originals.csv') # using pandas to read the csv file\n",
    "netflix_origionals = netflix_origionals[['Title','Seasons','Length','Netflix Exclusive Regions','Status']] # select the columns to keep\n",
    "netflix_origionals = netflix_origionals.where((pd.notnull(netflix_origionals)), None) # convert empty values to \"None\" values\n",
    "netflix_origionals.drop_duplicates(subset =\"Title\", \n",
    "                     keep = 'first', inplace = True) # delete duplicate values \n",
    "netflix_origionalsList = [tuple(l) for l in netflix_origionals.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "#print(netflix_origionalsList) #: data for original_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_stocks = pd.read_csv('NFLX.csv', parse_dates=['Date']) # using pandas to read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDim = pd.DataFrame({'date': pd.date_range(start='2002-05-23', end='2020-08-03')}) # create a dataframe that has dates ranging from 2002-05-23 to 2020-08-03\n",
    "dateDim['date_id'] = dateDim.index + 1 # create date_id column and assign id numbers starting from 1\n",
    "dateDim['date'] = dateDim['date'].dt.strftime(\"%Y-%m-%d\") # format date column to YYYY-MM-DD\n",
    "dateDim['year'] = pd.DatetimeIndex(dateDim['date']).year # using the year information from date colunn to create year column\n",
    "dateDim = dateDim.reindex(columns=['date_id','date','year']) # re-arrange the order of columns\n",
    "#dateDim.date = pd.to_datetime(dateDim.date)\n",
    "dateDim.date_id = dateDim.date_id.astype(str) # convert data in date column to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDimList = [tuple(l) for l in dateDim.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "# dateDimList: data for date_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDim.date = pd.to_datetime(dateDim.date) # convert data in date column to datatype date\n",
    "\n",
    "factsStockDF = pd.merge(netflix_stocks, dateDim, left_on='Date', right_on='date', how='inner') # inner join dataframes netflix_stocks and dataDim on date\n",
    "factsStockDF = factsStockDF.drop(['Date', 'date', 'year'], axis=1) # delete columns that are not needed\n",
    "factsStockDF = factsStockDF.reindex(columns=['date_id','Open','High','Low','Close','Adj Close', 'Volume']) # re-arrange the order of columns\n",
    "# factsStockDF['Date'] = factsStockDF['Date'].dt.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsStockList = [tuple(l) for l in factsStockDF.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "# factsStockList: data for facts_stock_prices table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRating = pd.merge(netflix_titles, netflix_origionals, left_on='title', right_on='Title', how='left') # left join dataframes netflix_titles and netflix_originals on titles\n",
    "factsRating.date_added = pd.to_datetime(factsRating.date_added) # convert data in date_added column to datatype date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = pd.merge(factsRating, dateDim, left_on='date_added', right_on='date', how='left') # left join dataframes factsRating and dateDim on date_added/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = factsRatingDF[['show_id','title','Title','date_id','rating']] # select only columns needed \n",
    "# factsRatingDF['date_id'] = factsRatingDF['date_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingDF = factsRatingDF.where((pd.notnull(factsRatingDF)), None) # convert empty values to \"None\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "factsRatingList = [tuple(l) for l in factsRatingDF.values.tolist()] # format data into a list of tuples before inserting to database\n",
    "#print(factsRatingList) # data for facts_IMDB_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# Establish the database connection\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Drop the table if it already exists\n",
    "cursor.execute(\"DROP TABLE IF EXISTS show_dim;\")\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable1 = \"\"\"CREATE TABLE show_dim(\n",
    "                 show_id INT not null,\n",
    "                 type VARCHAR(255) null,\n",
    "                 title VARCHAR(255) not null,\n",
    "                 director VARCHAR(255) null,\n",
    "                 cast MEDIUMTEXT null,\n",
    "                 country VARCHAR(255) null,\n",
    "                 duration VARCHAR(255) null,\n",
    "                 description MEDIUMTEXT null,\n",
    "                 PRIMARY KEY (show_id, title));\"\"\"\n",
    "\n",
    "cursor.execute(createTable1)\n",
    "\n",
    "insertData1 = \"INSERT INTO show_dim VALUES (%s,%s,%s,%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData1, showDimList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS original_dim;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable2 = \"\"\"CREATE TABLE original_dim(\n",
    "                  original_title VARCHAR(255) not null,\n",
    "                  seasons VARCHAR(255) null,\n",
    "                  length VARCHAR (255) null,\n",
    "                  regions VARCHAR (255) null,\n",
    "                  status VARCHAR (255) null,\n",
    "                  PRIMARY KEY (original_title));\"\"\"\n",
    "\n",
    "cursor.execute(createTable2)\n",
    "\n",
    "insertData2 = \"INSERT INTO original_dim VALUES (%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData2, netflix_origionalsList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create date_dim table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS date_dim;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable3 = \"\"\"CREATE TABLE date_dim(\n",
    "                  date_id VARCHAR(50) not null,\n",
    "                  date DATE null,\n",
    "                  year INT null,\n",
    "                  PRIMARY KEY (date_id));\"\"\"\n",
    "\n",
    "cursor.execute(createTable3)\n",
    "\n",
    "insertData3 = \"INSERT INTO date_dim VALUES (%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData3, dateDimList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create facts_imdb_rating table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS facts_imdb_rating;\")\n",
    "\n",
    "# Tạo bảng mới\n",
    "createTable5 = \"\"\"\n",
    "CREATE TABLE facts_imdb_rating (\n",
    "    show_id INT NOT NULL,\n",
    "    title VARCHAR(255) NOT NULL,\n",
    "    original_title VARCHAR(255),\n",
    "    date_id VARCHAR(50),\n",
    "    rating FLOAT,\n",
    "    PRIMARY KEY (show_id),\n",
    "    FOREIGN KEY (show_id) REFERENCES show_dim(show_id),\n",
    "    FOREIGN KEY (original_title) REFERENCES original_dim(original_title),\n",
    "    FOREIGN KEY (date_id) REFERENCES date_dim(date_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(createTable5)\n",
    "\n",
    "insertData5 = \"INSERT INTO facts_imdb_rating VALUES (%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData5, factsRatingList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(1146, \"Table 'netflix_datawarehouse.movie_genre' doesn't exist\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Chèn dữ liệu vào bảng movie_genre\u001b[39;00m\n\u001b[0;32m     56\u001b[0m insert_movie_genre \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO movie_genre (show_id, genre_id) VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m);\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_movie_genre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_genres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m db\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Đóng kết nối\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\cursors.py:182\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    180\u001b[0m     q_postfix \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_execute_many\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq_postfix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_stmt_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(query, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\cursors.py:220\u001b[0m, in \u001b[0;36mCursor._do_execute_many\u001b[1;34m(self, prefix, values, postfix, args, max_stmt_length, encoding)\u001b[0m\n\u001b[0;32m    218\u001b[0m         sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     sql \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 220\u001b[0m rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpostfix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m rows\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rows\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\cursors.py:153\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[1;32m--> 153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\cursors.py:322\u001b[0m, in \u001b[0;36mCursor._query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    320\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[1;32m--> 322\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\connections.py:563\u001b[0m, in \u001b[0;36mConnection.query\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    561\u001b[0m     sql \u001b[38;5;241m=\u001b[39m sql\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\connections.py:825\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    824\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 825\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mserver_status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\connections.py:1199\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1199\u001b[0m         first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1201\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n\u001b[0;32m   1202\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_ok_packet(first_packet)\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\connections.py:775\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m     \u001b[43mpacket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\NGHIATHE\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (1146, \"Table 'netflix_datawarehouse.movie_genre' doesn't exist\")"
     ]
    }
   ],
   "source": [
    "\n",
    "# Kết nối với cơ sở dữ liệu\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Tạo bảng movie_genre\n",
    "\n",
    "# Chuẩn bị dữ liệu cho movie_genre\n",
    "# Ví dụ: netflix_titles có cột \"show_id\" và \"listed_in\"\n",
    "netflix_titles['genres'] = netflix_titles['listed_in'].str.split(', ')\n",
    "\n",
    "# Tạo danh sách các thể loại duy nhất\n",
    "unique_genres = set(genre for genres in netflix_titles['genres'] for genre in genres)\n",
    "genre_dict = {genre: idx+1 for idx, genre in enumerate(unique_genres)}\n",
    "\n",
    "# Chèn các thể loại vào bảng genre_dim\n",
    "cursor.execute(\"DROP TABLE IF EXISTS genre_dim;\")\n",
    "create_genre_dim = \"\"\"\n",
    "CREATE TABLE genre_dim (\n",
    "    genre_id INT AUTO_INCREMENT,\n",
    "    genre_name VARCHAR(255) NOT NULL,\n",
    "    PRIMARY KEY (genre_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_genre_dim)\n",
    "\n",
    "insert_genre_dim = \"INSERT INTO genre_dim (genre_name) VALUES (%s);\"\n",
    "cursor.executemany(insert_genre_dim, [(genre,) for genre in unique_genres])\n",
    "db.commit()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS show_genre;\")\n",
    "\n",
    "create_movie_genre = \"\"\"\n",
    "CREATE TABLE show_genre (\n",
    "    show_id INT NOT NULL,\n",
    "    genre_id INT NOT NULL,\n",
    "    PRIMARY KEY (show_id, genre_id),\n",
    "    FOREIGN KEY (show_id) REFERENCES facts_imdb_rating(show_id),\n",
    "    FOREIGN KEY (genre_id) REFERENCES genre_dim(genre_id)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_movie_genre)\n",
    "\n",
    "# Chuẩn bị dữ liệu cho movie_genre\n",
    "show_genres = []\n",
    "for _, row in netflix_titles.iterrows():\n",
    "    movie_id = row['show_id']\n",
    "    for genre in row['genres']:\n",
    "        show_genres.append((movie_id, genre_dict[genre]))\n",
    "\n",
    "# Chèn dữ liệu vào bảng movie_genre\n",
    "insert_movie_genre = \"INSERT INTO show_genre (show_id, genre_id) VALUES (%s, %s);\"\n",
    "cursor.executemany(insert_movie_genre, show_genres)\n",
    "db.commit()\n",
    "\n",
    "# Đóng kết nối\n",
    "db.close()\n",
    "\n",
    "print(\"Bảng movie_genre và liên kết đã được thiết lập thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create facts_stock_prices table and insert data into it\n",
    "db = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"netflix_datawarehouse\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS facts_stock_prices;\") # delete the table if it already exists\n",
    "\n",
    "# create table with attributes based on the dimensional model\n",
    "createTable6 = \"\"\"CREATE TABLE facts_stock_prices(\n",
    "                  date_id VARCHAR(50) not null,\n",
    "                  open FLOAT null,\n",
    "                  high FLOAT null,\n",
    "                  low FLOAT null,\n",
    "                  close FLOAT null,\n",
    "                  adj_close FLOAT null,\n",
    "                  volume FLOAT null,\n",
    "                  PRIMARY KEY (date_id),\n",
    "                  FOREIGN KEY (date_id) REFERENCES date_dim(date_id)\n",
    "                  );\"\"\"\n",
    "\n",
    "cursor.execute(createTable6)\n",
    "\n",
    "insertData6 = \"INSERT INTO facts_stock_prices VALUES (%s,%s,%s,%s,%s,%s,%s);\" # insert data into table\n",
    "cursor.executemany(insertData6, factsStockList)\n",
    "db.commit()\n",
    "\n",
    "db.close() # close the connection to mysql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
